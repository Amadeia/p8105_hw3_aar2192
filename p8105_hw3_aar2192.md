p8105\_hw3\_aar2192
================
Amadeia Rector
10/12/2018

Problem 1
---------

#### Loading data from BRFSS

``` r
devtools::install_github("p8105/p8105.datasets", force = TRUE)
```

    ## Downloading GitHub repo p8105/p8105.datasets@master
    ## from URL https://api.github.com/repos/p8105/p8105.datasets/zipball/master

    ## Installing p8105.datasets

    ## '/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file  \
    ##   --no-environ --no-save --no-restore --quiet CMD INSTALL  \
    ##   '/private/var/folders/h0/745bvl6520dfjw96s7mndz_40000gq/T/RtmpsAdCMc/devtools40f9b0af1c/P8105-p8105.datasets-21f5ad1'  \
    ##   --library='/Library/Frameworks/R.framework/Versions/3.5/Resources/library'  \
    ##   --install-tests

    ## 

``` r
library(p8105.datasets)
data("brfss_smart2010")
```

#### Cleaning BRFSS datasest

``` r
brfss_smart2010_clean =
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  separate(county, into = c("trash", "county"), sep = " - ") %>% 
  select(-trash) %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = factor(response, levels = c("Excellent", "Very good", "Good","Fair","Poor")))
```

#### In 2002, which states were observed at 7 locations?

``` r
brfss_smart2010_clean %>% 
  filter(year == 2002) %>%
  group_by(state, year) %>%
  summarize(distinct_counties = n_distinct(county)) %>% 
  filter(distinct_counties==7)
```

    ## # A tibble: 3 x 3
    ## # Groups:   state [3]
    ##   state  year distinct_counties
    ##   <chr> <int>             <int>
    ## 1 CT     2002                 7
    ## 2 FL     2002                 7
    ## 3 NC     2002                 7

Connecticut, Florida, and North Carolina were observed in 7 locations or counties in 2002.

#### Spaghetti plot for number of locations 2002-10

``` r
  brfss_smart2010_clean %>% 
  group_by(state, year) %>%
  summarize(distinct_counties = n_distinct(county)) %>% 
  ggplot(aes(x = year, y = distinct_counties, group = state)) +
    geom_line(aes(color = state))+
  labs(title = "Counties observed per year by state", x = "Time (years)", y = "Number of counties") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
```

<img src="p8105_hw3_aar2192_files/figure-markdown_github/spag_plot-1.png" width="90%" />

#### Table showing proportion of excellent responses for years 2002, 2006, and 2010 by NY counties

``` r
brfss_smart2010_clean %>% 
  filter(state == "NY", year %in% c(2002, 2006, 2010), response == "Excellent") %>%
  group_by(county) %>% 
  summarize(mean_excellent = mean(data_value), sd_excellent = sd(data_value)) %>% 
  select(county, mean_excellent, sd_excellent) %>% 
  rename("Mean excellent response" = mean_excellent, "Standard deviation excellent response" = sd_excellent) %>% 
  knitr::kable()
```

| county             |  Mean excellent response|  Standard deviation excellent response|
|:-------------------|------------------------:|--------------------------------------:|
| Bronx County       |                 17.60000|                                     NA|
| Erie County        |                 17.20000|                                     NA|
| Kings County       |                 20.36667|                              1.7672955|
| Monroe County      |                 22.40000|                                     NA|
| Nassau County      |                 24.93333|                              2.8219379|
| New York County    |                 27.50000|                              1.5394804|
| Queens County      |                 19.63333|                              1.3576941|
| Suffolk County     |                 24.10000|                              3.2787193|
| Westchester County |                 26.45000|                              0.6363961|

#### Five panel plot of distribution of responses over time

``` r
brfss_response_df=
  brfss_smart2010_clean %>% 
  group_by(state, year, response) %>% 
  summarize(mean_response = mean(data_value))

ggplot(brfss_response_df, aes(x = year, y = mean_response, color = state))+
  geom_point(alpha = .5) +
  facet_grid(.~response) +
  labs( y = "Mean responses", x = "Time (year)") +
  theme(legend.position = "none", panel.spacing = unit(2, "lines")) +
  scale_x_continuous(breaks = c(2002, 2006, 2010))
```

    ## Warning: Removed 21 rows containing missing values (geom_point).

<img src="p8105_hw3_aar2192_files/figure-markdown_github/five_panel_plot-1.png" width="90%" /> \#\#Problem 2

#### Loading instacart data

``` r
data("instacart")
View(instacart)
summary(unique(instacart$department))
```

    ##    Length     Class      Mode 
    ##        21 character character

``` r
summary(unique(instacart$aisle))
```

    ##    Length     Class      Mode 
    ##       134 character character

``` r
summary(unique(instacart$product_name))
```

    ##    Length     Class      Mode 
    ##     39123 character character

``` r
summary(is.na(instacart))
```

    ##   order_id       product_id      add_to_cart_order reordered      
    ##  Mode :logical   Mode :logical   Mode :logical     Mode :logical  
    ##  FALSE:1384617   FALSE:1384617   FALSE:1384617     FALSE:1384617  
    ##   user_id         eval_set       order_number    order_dow      
    ##  Mode :logical   Mode :logical   Mode :logical   Mode :logical  
    ##  FALSE:1384617   FALSE:1384617   FALSE:1384617   FALSE:1384617  
    ##  order_hour_of_day days_since_prior_order product_name     aisle_id      
    ##  Mode :logical     Mode :logical          Mode :logical   Mode :logical  
    ##  FALSE:1384617     FALSE:1384617          FALSE:1384617   FALSE:1384617  
    ##  department_id     aisle         department     
    ##  Mode :logical   Mode :logical   Mode :logical  
    ##  FALSE:1384617   FALSE:1384617   FALSE:1384617

``` r
summarize(instacart, mean(days_since_prior_order))
```

    ## # A tibble: 1 x 1
    ##   `mean(days_since_prior_order)`
    ##                            <dbl>
    ## 1                           17.1

#### Describing the instacart data

The dataframe is in tibble format. There are 1,384,617 rows and 15 columns (variables) in the instacart dataset. The variables are listed as orded\_id, product\_id, add\_to\_cart\_order, reordered, user\_id, eval\_set, order\_number, order\_dow, order\_hour\_of\_day, days\_since\_prior\_order, product\_name, aisle\_id, department\_id, aisle, and department.

Most likely the key variables are department, aisle, order\_hour\_of\_day, product\_name. This would be because we might be interested in knowing what department and in what aisle are most products found. Then, we would want to know what are the most bought items, and at what time of the day do customers shop.

There are 21 departments, 134 aisles, and 39123 different product\_names. The mean number of days since prior order is 17.1 days. There doesn't appear to be any missing data.

#### How many aisles are there, and which aisles are the most items ordered from?

``` r
n_distinct(instacart$aisle)
```

    ## [1] 134

``` r
instacart %>% 
  group_by(aisle) %>%
  summarize(number_products = n()) %>% 
  arrange(min_rank(desc(number_products)))
```

    ## # A tibble: 134 x 2
    ##    aisle                         number_products
    ##    <chr>                                   <int>
    ##  1 fresh vegetables                       150609
    ##  2 fresh fruits                           150473
    ##  3 packaged vegetables fruits              78493
    ##  4 yogurt                                  55240
    ##  5 packaged cheese                         41699
    ##  6 water seltzer sparkling water           36617
    ##  7 milk                                    32644
    ##  8 chips pretzels                          31269
    ##  9 soy lactosefree                         26240
    ## 10 bread                                   23635
    ## # ... with 124 more rows

There are 134 different aisles. The fresh vegetables aisle is the aisle where the most products are ordered from.

#### Plot of items ordered by aisle

``` r
data_for_insta_plot =
  instacart %>% 
  group_by (aisle, department) %>% 
  summarize(number_products = n()) %>%
  arrange(department)

  data_for_insta_plot$aisle =
    factor(data_for_insta_plot$aisle, levels = unique(data_for_insta_plot$aisle))
  
  data_for_insta_plot %>% 
  ggplot(aes(x = aisle, y = number_products)) + 
  geom_point(aes(color = department)) +
  labs(title = "Products ordered per aisle within departments",
       y = "Products ordered", x = "Aisles") +
  scale_x_discrete(breaks = NULL) +
  theme(plot.title = element_text(hjust = 0.5))
```

<img src="p8105_hw3_aar2192_files/figure-markdown_github/plot_products_ordered-1.png" width="90%" />

#### Table of most popular items for aisles: “baking ingredients”, “dog food care”, and “packaged vegetables fruits”

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", 
                      "packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>% 
  summarize(product_amt = n()) %>% 
  filter(min_rank(desc(product_amt)) < 2) %>% 
  rename("product name" = product_name, "Total sold" = product_amt) %>% 
  knitr::kable()
```

| aisle                      | product name                                  |  Total sold|
|:---------------------------|:----------------------------------------------|-----------:|
| baking ingredients         | Light Brown Sugar                             |         499|
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |          30|
| packaged vegetables fruits | Organic Baby Spinach                          |        9784|

#### Table showing mean hour of day for pink lady apples and coffee ice cream

``` r
  instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name,order_dow) %>% 
  summarize(mean_hour_dow = round(mean(order_hour_of_day))) %>% 
  spread(key = order_dow, value = mean_hour_dow) %>% 
  rename("Product" = product_name, "Sun" = '0', "Mon" = '1', "Tues" = '2', "Wed" = '3', "Thurs" = '4', "Fri" = '5', "Sat" = '6') %>%
  knitr::kable()
```

| Product          |  Sun|  Mon|  Tues|  Wed|  Thurs|  Fri|  Sat|
|:-----------------|----:|----:|-----:|----:|------:|----:|----:|
| Coffee Ice Cream |   14|   14|    15|   15|     15|   12|   14|
| Pink Lady Apples |   13|   11|    12|   14|     12|   13|   12|
